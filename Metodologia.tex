\chapter{Metodologia}
\label{Metodologia}
Neste capítulo será apresentada a metodologia para aplicação da EG para geração de heurísticas de alto nível para um \textit{framework} hiper-heurístico  para o problema de dobramento de proteínas. Esta proposta é baseada no trabalho desenvolvido por Sabar et al. \cite{sabar2015automatic}, o qual  utilizou GEP (\textit{gene expression programming}) com objetivo de gerar os componentes de um \textit{framework} hiper-heurístico para diversos domínios de problemas. Os testes de generalidade realizados por Sabar, utilizando os 6 domínios providos pelo \textit{framework} hiper-heurístico HyFlex, apresentaram bons resultados em relação às outras estratégias hiper-heurísticas do estado da arte. O bom desempenho do estudo de Sabar motivou a criação da presente proposta. Pretende-se utilizar EG ao invés de GEP e aplicar ao PDP utilizando o modelo HP-2D. A representação de coordenadas relativas, descrita na subseção \ref{subsubsection:modeloHP}, será utilizada pois segundo o estudo realizado por Krasnogor et al. \cite{krasnogor1999protein} apresentam um maior potencial em conduzir os algoritmos a resultados melhores. Para representar as soluções ao problema PDP utilizando coordenadas relativas um esquema de codificação foi definido.  As coordenadas são traduzidas em valores inteiros da seguinte maneira F->0, E->1 e D->2. Portanto o alfabeto utilizado para representar as soluções para é definido como $\{0,1,2\}$.


Como mencionado anteriormente, um \textit{framework} hiper-heurístico possui dois níveis: alto (\textit{high-level heuristics}) e baixo (\textit{low-level heuristics}). Nesta proposta as heurísticas de alto nível são compostas por: um mecanismo de seleção e um critério de aceitação. Já as heurísticas de baixo nível consistem em um conjunto de heurísticas, selecionadas de estudos anteriores, um mecanismo de memória e uma função de \textit{fitness}. 

\section{\textit{Heurísticas de alto nível}}
\label{sec:highlevelheuristics}
Nas heurísticas de alto nível, a responsabilidade do mecanismo de seleção é selecionar, de um \textit{pool} de heurísticas de baixo nível, a heurística que for mais adequada naquele momento. Geralmente, a escolha da heurística de baixo nível é crucial para uma boa exploração do espaço de busca, evitando que a busca fique confinada em uma região específica \cite{sabar2015automatic}. O objetivo do critério de aceitação é auxiliar o processo de busca a evitar mínimos locais assim como explorar diferentes regiões através do aceite ou rejeição de soluções geradas \cite{chakhlevitch2008hyperheuristics}. Esperasse que um bom critério de aceitação deva atingir um bom equilíbrio entre aceitar soluções melhores assim como soluções diversificadas se a busca estiver presa em um mínimo local \cite{sabar2015automatic}. Isto posto, a presente proposta projeta a geração online dos componentes de uma heurística de alto nível (mecanismo de seleção e critério de aceitação) para um \textit{framework} hiper-heurístico. A figura \ref{fig:proposedFramework} apresenta o \textit{framework} proposto.

 \begin{figure}[!htb]
 	\centering
 	\includegraphics[scale=.98]{HH/proposedFramework.png}
 	\caption{\textit{Framework} proposto. \\ Fonte: Adaptado de \cite{sabar2014automatic}}
 	\label{fig:proposedFramework}
 \end{figure}
 
 Como mencionado na subseção \ref{subsubsection:EvolucaoGramatical}, a EG utiliza vetores de valores inteiros com tamanho variável para representar seus indivíduos. Dessa maneira, a EG junta as vantagens tanto de algoritmos genéticos como de programação genética para evoluir populações de programas de computador.
 Uma gramática específica foi definida para decodificar os vetores inteiros em  heurísticas de alto nível. A gramática apresentada em \ref{grammar:proposedGrammar} foi definida para gerar mecanismos de seleção e critérios de aceitação. 
 \\
 
 \begin{Grammar}
 	\begin{grammar}
 		<hh-selection> ::= <selection-mechanism> <acceptance-criterion> 
 		
 		<selection-mechanism> :==  <selection-terminal>   
 		\alt <selection-mechanism> <selection-function> <selection-mechanism> 
 		\alt (<selection-mechanism> <selection-function> <selection-mechanism>) 
 		
 		<selection-terminal> :== 
 		RC 
 		| Cbest 
 		| Ccurrent 
 		| Caccept 
 		| Cava 
 		| Cr
 		
 		<selection-function> :== + 
 		| - 
 		| * 
 		| \%
 		
 		<acceptance-criterion> ::== <acceptance-terminal> 
 		\alt <acceptance-criterion> <accpetance-function>
 		<acceptance-criterion>
 		\alt (<acceptance-criterion>  <accpetance-function> <acceptance-criterion>) 
 		
 		<acceptance-terminal> :== PF | CF | CI | TI
 		
 		<acceptance-function> :== + | - | * | \% | $e^x$
 		
 		
 	\end{grammar}
 	\caption{Gramática definida para gerar  heurísticas de alto nível}
 	\label{grammar:proposedGrammar}
 \end{Grammar}
 
 
 
 O conjunto de funções e terminais apresentado na gramática \ref{grammar:proposedGrammar} foi desenvolvido baseado nos conjuntos  propostos no  trabalho relacionado \cite{sabar2014automatic}. Uma explicação detalhada de cada terminal para os mecanismos de seleção $(selection-terminal)$ é apresentada em seguida:

 
 \begin{itemize}
	\item RC (\textit{Reward Credit}): Este terminal representa a recompensa que uma determinada heurística de baixo nível deve receber baseado no seu desempenho durante o processo de busca. Quando a i-ésima heurística é aplicada a melhoria para a solução é computada. O cálculo da melhoria é dado por: $M(i) = (|f1 -f2|/f1) *100$ se $f2$< $f1$. Onde $f1$ é a qualidade da solução corrente e $f2$ é a qualidade da solução resultante após a aplicação da i-ésima heurística. 
	A melhoria obtida é salva em uma janela deslizante (FIFO) de tamanho W. O crédito de qualquer heurística de baixo nível é então atribuído como o máximo valor na janela deslizante correspondente. A ideia por trás deste terminal é: heurísticas de baixo nível que não são usadas com frequência mas que alteram a solução com grandes melhorias tendem a ter mais preferência do que aquelas que geram pequenas melhorias. Portanto as heurísticas que trazem frequentes, mas pequenas melhorias irão ter menos probabilidade de serem selecionadas.
	\item $C_{best}$: Número de vezes que a i-ésima heurística de baixo nível atualizou a melhor solução conhecida. Este terminal favorece as heurísticas de baixo nível que obtiveram êxito em melhorar a melhor solução conhecida até o momento. Este terminal é útil para sistematicamente melhorar o atual mínimo local.
	\item $C_{current}$: Número de vezes que a i-ésima heurística de baixo nível atualizou a solução atual. Este terminal favorece as heurísticas de baixo nível que obtém êxito em atualizar a solução corrente. Este terminal serve para deixar a busca concentrada próxima à solução corrente.
	\item $C_{accept}$: Número de vezes que a solução gerada pela i-ésima heurística de baixo nível foi aceita pelo critério de aceitação. Este terminal favorece heurísticas de baixo nível que podem ajudar a escapar de um mínimo local.
	\item $C_{ava}$: A média de melhorias anteriores da i-ésima heurística de baixo nível durante o progresso da busca. Este terminal favorece heurísticas de baixo nível que realizaram grandes melhorias em média.
	\item $C_r$: O número de vezes que a i-ésima heurística de baixo nível foi classificada como primeira.  
 \end{itemize} 
 
 O conjunto de funções para mecanismos de seleção $(selection-function)$ é apresentado abaixo:
  
 \begin{itemize}
	\item +: Adiciona as duas entradas.
	\item -: Subtrai a segunda entrada da primeira.
	\item *: Multiplica as duas entradas.
	\item \%: Divisão protegida, isto é, se o denominador for 0 o altera para 0,001.
 \end{itemize}
 
 
 
 O conjunto terminal $(acceptance-terminal)$ para critérios de aceitação é apresentado em seguida:
 
 \begin{itemize}
	\item Delta: A diferença da qualidade entre  solução corrente e a solução descendente.
	\item PF: A qualidade da solução anterior.
	\item CF: A qualidade da solução atual.
	\item CI: Iteração corrente.
	\item TI: Número de iterações.
 \end{itemize}
 
 O conjunto de funções para critérios de aceitação $(acceptance-function)$ é apresentado abaixo:
 
 \begin{itemize}
	\item +: Adiciona as duas entradas.
	\item -: Subtrai a segunda entrada da primeira.
	\item $e^x$: O resultado elevado à sua potencia (número de Euler).
	\item *: Multiplica as duas entradas.
	\item \%: Divisão protegida, isto é, se o denominador for 0 o altera para 0,001.
 \end{itemize}
 
 Utilizando a gramática apresentada e vetores de inteiros é possível gerar heurísticas de alto nível. Os conjuntos terminais da gramática apresentam estatísticas sobre as heurísticas de baixo nível e estas são a matéria prima para a construção dos componentes das heurísticas de alto nível de um \textit{framework} hiper-heurístico. 
 
 O próximo passo consiste em evoluir uma população de vetores de inteiro, gerados de maneira aleatória, utilizando o processo evolutivo descrito na subseção 
 \ref{subsubsection:EvolucaoGramatical}. %A figura BLAH apresenta o processo geral da evolução gramatical proposta.
 

 \subsection{Função de \textit{Fitness}}
 
 Para avaliar os indivíduos gerados durante o processo de busca da evolução gramatical uma função de \textit{fitness} foi desenvolvida baseada na função proposta por Sabar el al. \cite{sabar2014automatic}. O objetivo da função é avaliar as heurísticas de alto nível geradas (indivíduos). A probabilidade de selecionar um determinado indivíduo é alterada de acordo com a qualidade da melhor solução retornada pela execução do \textit{framework} hiper-heurístico composto pelo mecanismo de seleção e critério de aceitação codificados por um dado indivíduo. A qualidade retornada pela solução pode ser pior ou melhor do que a solução utilizada como entrada para o \textit{framework} hiper-heurístico. Suponha que $f_i$ e $f_b$ representem a qualidade da solução inicial e da retornada, $Nh$ representa o número de indivíduos da EG e $Ph[]$ o array de probabilidades de seleção dos indivíduos da EG. Agora suponha que ao aplicar o $i$-ésimo indivíduo e obtido uma melhoria na qualidade da solução, a retribuição para o $i$-ésimo indivíduo é calcula: $Ph[i] = Ph[i] + \sigma $ onde $\sigma = (f_i - f_b)/(f_i + f_b)$. Os demais indivíduos $j \in \{1, ..., Nh\} ~e~ j \neq i$ são penalizados: $Ph[j] = Ph[j] - (\sigma / (Nh - 1))$. Caso contrário (se a solução retornada não for melhor que a utilizada como entrada), uma penalização é aplicada ao $i$-ésimo indivíduo: $Ph[i] = Ph[i] - |\sigma \times \alpha|$ onde $\alpha =$ iteração corrente $/$ número total de iterações. Os demais indivíduos $j \neq i$ recebem uma recompensa: $Ph[j] = 
  Ph[j] + (|\sigma| \times \alpha / (Nh -1))$. A motivação por trás de  diminuir a probabilidade de outros indivíduos é reduzir as chances destes serem selecionados. Inicialmente, a probabilidade de cada indivíduo é calculada: decodificando o  respectivo mecanismo de seleção e criério de aceitação e o executando dentro de um \textit{framework} hiper-heurístico por um tempo determinado de iterações.
 
 \subsection{Critério de Parada}
 
 Para terminar o processo da EG um número máximo de iterações que não obtêm melhora será utilizado como condição de parada. Note que este critério de parada é referente a parada do processo da EG e não das execuções dos indivíduos dentro do \textit{framework} hiper-heurístico, que ocorrem durante o progresso da EG. 
 
 \section{\textit{Low Level Heuristics}} 
 
 Nas heurísticas de baixo nível o \textit{framework} proposto possui 3 componentes principais: um conjunto de heurísticas de baixo nível e um mecanismo de memória.
 
 \subsection{Conjunto de \textit{Low Level Heuristics}}
 Um conjunto de heurísticas de baixo nível foi selecionado a partir de uma revisão bibliográfica dos trabalhos, mais recentes, referentes ao PDP utilizando o modelo HP-2D. 
 
 
 \begin{itemize}
	\item \textit{Two Points Crossover} (2X): Este operador seleciona, de maneria aleatória, 2 pontos de cruzamento dividindo os indivíduos em 3 partes. Os genes entre as posições selecionadas são trocados entre os pais de modo a gerar dois novos filhos \cite{benitez2015algoritmo}, conforme apresentado na figura \ref{fig:twopointscrossover}.
	

	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/TwoPointsCrossover.png}
		\caption{Exemplo de aplicação do operador 2x. \\Fonte Autoria Própria}
		\label{fig:twopointscrossover}
	\end{figure}
	
			

	
	\item \textit{Multi Points Crossover} (MPX): Semelhante ao 2X porém com c pontos, baseado na função $c = int(n * 0.1)$, $n$ é o tamanho da sequencia. O operador MPX é utilizado para promover diversidade estrutural realizando uma mescla randômica entre os pais, embora não tão radical quanto o \textit{Uniform  Crossover} \cite{sabar2014automatic}. Um exemplo de aplicação do operador MPX é apresentado na imagem \ref{fig:multipointscrossover}
	
	
		\begin{figure}[!htb]
			\centering
			\includegraphics{Imagens/MultiPointsCrossover.png}
			\caption{Exemplo de aplicação do operador MPX. \\Fonte Autoria Própria}
			\label{fig:multipointscrossover}
		\end{figure}
	\item \textit{Segment Mutation} (SMUT): Altera um número aleatório (5 a 7) de genes consecutivos para direções distintas. Esta heurística introduz grandes mudanças na conformação, e tem um grande probabilidade de criar colisões. Um mecanismo de reparação simples é aplicado no descendente gerado. A imagem \ref{fig:segmentMutation} apresenta um exemplo da aplicação do SMUT.
	
	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/segmentMutation.png}
		\caption{Exemplo de aplicação do operador SMUT. \\Fonte Autoria Própria}
		\label{fig:segmentMutation}
	\end{figure}
	
	
	\item \textit {Exhaustive Search Mutation} (EMUT): Esta heurística seleciona um gene aleatório e testa todas as outras direções possíveis e irá manter a alteração que conseguir aumentar a qualidade da conformação. O \textit{tradeoff} deste operador: é demandar 4 avaliações de \textit{fitness}, as quais devem ser levadas em consideração. Esta heurística tem grande potencial de melhorar o \textit{fitness} de uma conformação. 
	
	
	\item \textit{Local Move Operator} (LM): Esta heurística troca direções entre dois genes aleatórios consecutivos. Existem algumas condições para que esta heurística possa ser executada, por exemplo, as novas direções não podem criar movimentos redundantes. Este operador introduz um "movimento de esquina". A figura \ref{fig:localMoveOperator} apresenta um exemplo da aplicação do operador LM. 
	
	
	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/LocalMoveOperator.png}
		\caption{Exemplo de aplicação do operador LM. \\Fonte Autoria Própria}
		\label{fig:localMoveOperator}
	\end{figure}
	
	
	\item \textit{Loop Move Operator} (LPM): Da mesma maneira que a heurística LM esta heurística troca direções entre dois genes que estão há 5 genes de distância na sequência criando um movimento de \textit{loop}. A figura  \ref{fig:loopMoveOperator} apresenta um exemplo da aplicação do operador LPM.

	
	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/LoopMoveOperator.png}
		\caption{Exemplo de aplicação do operador LPM. \\Fonte Autoria Própria}
		\label{fig:loopMoveOperator}
	\end{figure}
	
	\item \textit{Opposite Mutation} (OM): Esta heurística troca as direções, para direção oposta, de uma sequência de genes entre dois genes $(i,j)$ selecionados de maneira aleatória. A direção 0 ($F$) não possui oposta, portanto é mantida. Para exemplificar suponha esta solução hipotética para uma sequência de 5 aminoácidos: $\{0,1,2,1,2\}$ se tornaria $\{0,2,1,2,1\}$. A figura \ref{fig:oppositeMutation} apresenta um exemplo da aplicação do operador OM.
	
	
	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/OppositeMutation.png}
		\caption{Exemplo de aplicação do operador OM. \\Fonte Autoria Própria}
		\label{fig:oppositeMutation}
	\end{figure}
	

	
 \end{itemize} 
 
 
 
 
 
 
 
 \subsection{Mecanismo de Memória}
 
 A maioria dos \textit{frameworks} hiper-heurísticos propostos na literatura operam sobre uma única solução \cite{chakhlevitch2008hyperheuristics, burke2013hyper}. Blum et al. \cite{blum2011hybrid} menciona que utilizar uma única solução pode restringir a capacidade em explorar um espaço de busca grande e restrito. Dessa maneira, Sabar et al. \cite{sabar2014automatic} propôs uma abordagem que utiliza um mecanismo de memória, assim como Talbi el al. \cite{talbi2006cosearch}, o qual contém um conjunto de soluções com alta qualidade e diversas, atualizado conforme o progresso da busca. Nesta proposta o mecanismo de memória tem a responsabilidade de armazenar soluções para o problema PDP utilizando a representação de coordenadas relativas para o modelo HP-2D. Esta representação possibilita a geração de soluções inválidas, que possuem colisões. Tradicionalmente algoritmos evolutivos inicializam suas populações iniciais de maneira aleatória, por conta disto  muitas soluções inválidas, ao problema PDP, podem ser geradas na inicialização. Isto geralmente  ocasiona perda de tempo de processamento, por conta da grande quantidade de conformações inválidas, antes que bons resultados sejam obtidos. Diante disto Benítez et al. \cite{benitez2015algoritmo} propôs uma estratégia especializada de inicialização. Benítez et al. \cite{benitez2015algoritmo} inicializou a população, de seu algoritmo genético, dividida em duas partes. Uma gerada aleatoriamente, com indivíduos que potencialmente possuem colisões. E uma segunda parte onde todos os indivíduos são livres de colisões. Uma configuração é utilizada para definir a proporção entre as duas partes da população inicial. Para garantir que os indivíduos não possuam colisões uma estratégia de \textit{backtracking} deve ser utilizada. Nesta proposta, pretende-se utilizar uma estratégia similar, adaptada ao modelo HP-2D. As possíveis conformações podem ser representadas por um caminho em um grafo orientado estruturado como uma árvore. Consequentemente, cada nó da árvore representa uma solução candidata parcial $c$, desde o primeiro aminoácido até o ultimo sendo considerado. Portanto, um caminho até um nó folha representa uma conformação completa. As arestas do grafo representam o movimento de cada aminoácido relativo a seu predecessor. A figura \ref{fig:backtrackInit}  apresenta um fragmento do espaço de busca para uma cadeia hipotética com 5 aminoácidos. O espaço de busca completo é grande totalizando  $5^4=625$ possibilidades, e não pode ser apresentado por questões de visualização.
 
 	\begin{figure}[!htb]
 		\centering
 		\includegraphics[scale=0.8]{Imagens/BacktrackingInit.png}
 		\caption{Fragmento BLAH. \\Fonte Autoria Própria}
 		\label{fig:backtrackInit}
 	\end{figure}
 	
 	Na figura \ref{fig:backtrackInit} (TODO: arrumar imagem e explicação para o HP-2D) o caminho apresentado pelas setas azuis representa uma solução que gera uma conformação válida (sem colisões). A seta vermelha demonstra que se caso o ultimo passo fosse alterado de 0 para 1. Esta alteração causaria uma conformação inválida, pois posicionaria o ultimo aminoácido na posição 0,1,1 a qual já havia sido ocupada no segundo passo. 
 	A estratégia de inicialização com \textit{backtracking} irá começar posicionando o primeiro aminoácido na posição 0,0,0. Para posicionar o próximo aminoácido, um movimento é selecionado de maneira aleatória. Caso o movimento cause uma colisão, este movimento será marcado como uma má escolha e um novo movimento é selecionado aleatoriamente (do conjunto que restou sem o movimentos marcados como más escolhas). Caso todos os movimentos sejam marcados como má escolha a estratégia de \textit{backtracking} irá retornar de maneira recursiva para o aminoácido anterior e marcar a escolha em questão como um má escolha. A estratégia de \textit{backtracking} termina quando gerar um caminho na árvore que não possua colisões.
 	
 	
% 	e selecionando de maneira aleatória o movimento para o próximo 
% 	
% 	
% 	aminoácido. Caso este movimento cause uma colisão (seja posicionado em uma região da grade que já havia um aminoácido) o \textit{backtracking} entra em cena percorrendo a árvore de maneira recursiva 
 	 
  
 
% Para cada solução, uma matriz de frequência é associada afim de medir a diversidade da solução. A matriz de frequência irá armazenar a frequência que cada aminoácido foi atribuído para cada uma das direções possíveis $\{0,1,2,3,4\}$. A figura \ref{fig:frequencyMatrix} apresenta um exemplo de uma matriz de frequência para uma cadeia hipotética $HPPHHHP$ de 7 aminoácidos. Observando a figura  \ref{fig:frequencyMatrix} é possível notar que o aminoácido 0 foi atribuído a direção E (3), que significa esquerda, duas vezes, três vezes para a direção D (4), que significa direita e nenhuma vez para as direções F(0), D(1) e B(2). 
 
 
% 	\begin{figure}[!htb]
% 		\centering
% 		\includegraphics[scale=0.8]{Imagens/FrequencyMatrix.png}
% 		\caption{Fragmento BLAH. \\Fonte Autoria Própria}
% 		\label{fig:frequencyMatrix}
% 	\end{figure}
%
 
 A cada iteração a heurística de alto nível irá selecionar de maneira aleatória uma solução do mecanismo de memória; aplicar a heurística de baixo nível, selecionada pelo mecanismo de seleção. %, e atualizará a matriz de frequência associada à solução %. 
 Em seguida a qualidade e a diversidade da solução gerada precisam ser avaliadas. A qualidade de uma solução para o PDP utilizando o modelo HP: é inversamente proporcional à quantidade de interações entre aminoácidos hidrofóbicos. Portanto a qualidade de uma solução é dada pela quantidade de iterações H-H multiplicada por -1, conforme descrito na subseção \ref{subsubsection:modeloHP}.  As soluções geradas que tiverem a qualidade maior que todas as soluções contidas no mecanismo de memória substituirão a solução que tiver menor similaridade segundo a distância de \textit{Hamming} \cite{hamming1950error}. Se a qualidade de uma solução gerada não for maior que todas as soluções, mas melhor em relação a um sub-conjunto do mecanismo de memória, está substituirá a solução que tiver menor qualidade e menor similaridade do sub-conjunto. E por fim se a qualidade da solução gerada for pior que todas contidas no mecanismo de memória esta é descartada. A similaridade é considerada afim de manter a diversidade entre as soluções.  
 
 
 %Para avaliar a diversidade será utilizada a entropia da informação.  As equações \ref{equation:entropy1} e \ref{equation:entropy2} exemplificam o cálculo de entropia.
 
% \begin{equation}
%	 \label{equation:entropy1}
% 	 \epsilon_i = \frac{\sum\limits_{i=1}^e \frac{e_{ij}}{m}  . \log \frac{e_{ij}}{m}}{-log~e}
% \end{equation}
% 
%  \begin{equation}
%  	 \label{equation:entropy2}
%  \epsilon = \frac{\sum\limits_{i=1}^e \epsilon_i}{e}
%  \end{equation}
%  
%	 \noindent$e_{ij}$ é a frequência de alocação do aminoácido $i$ para a direção $j$; \\
%	 $m$ é o número de objetos; \\
%	 $\epsilon_i$ representa a entropia para o aminoácido $i$;
%	 $\epsilon$ representa a entropia para uma solução completa (todos os aminoácidos) ($0 <= \epsilon_i <= 1$). 
% 

  
  
\section{Processo geral} 

As principais etapas do \textit{framework} proposto serão apresentadas nesta seção.
Inicialmente uma população de indivíduos (heurísticas de alto nível: mecanismo de seleção e critério de aceitação) é gerada de maneira aleatória. O \textit{fitness} da população é calculado: inserindo os indivíduos em um \textit{framework} hiper-heurístico e o executando por um certo número de iterações. E de maneira iterativa selecionar indivíduos pais e aplicar os operadores de cruzamento, mutação, \textit{prune} e \textit{duplicate} para gerar descendentes. Para avaliar os descendentes os seguintes passos são executados:

\begin{enumerate}
	\item Cada indivíduo é decodificado em um mecanismo de seleção e um critério de aceitação. Os valores, descritos 	para o conjunto terminal na seção \ref{sec:highlevelheuristics}, de cada heurística de baixo nível serão utilizados como entrada para o mecanismo de seleção.
	\item Execução do mecanismo de seleção com objetivo de ordenar o conjunto heurísticas de baixo nível. As heurísticas de baixo nível são ordenadas da maior para a menor baseando-se no resultado da expressão referente ao mecanismo de seleção. 
	\item Selecionar uma solução do mecanismo de memória. Aplicar a heurística de baixo nível classificada com o maior valor e calcular a qualidade da solução gerada.
	\item Se a solução gerada for melhor do que a atual, a atual é substituída. Caso contrário a expressão referente critério de aceitação é executada. A solução gerada pela heurística de baixo nível é aceita caso o exponencial natural do valor, retornado pelo critério de aceitação, seja menor ou igual a 0.5 (a função $e^x$ retorna valores entre 0 e 1). Sabar et al. \cite{sabar2014automatic} menciona que este valor de 0.5 é sugerido pela literatura. 
	\item Aplicar a heurística de baixo nível, que foi selecionada pelo mecanismo de seleção, repetidamente até que não ocorram mais melhorias.
	\item Se não houverem mais melhorias, trocasse a heurística de baixo nível atual pela segunda melhor classificada, baseando-se no valor retornado pelo mecanismo de seleção.
	\item Se o \textit{framework} chegar ao fim da lista de heurísticas de baixo nível, é executado o mecanismo de seleção novamente e a lista de heurísticas de baixo nível é reordenada. A busca reinicia agora utilizando a heurística de baixo nível com maior valor para a expressão referente ao mecanismo de seleção.
	\item O \textit{framework} proposto continuará utilizando os componentes da heurística de alto nível (mecanismo de seleção e critério de aceitação) por um tempo pré-determinado de iterações.
	
\end{enumerate}
 
 
 
 
 
 
  
 
 







\section{Considerações Finais}
\label{Metodologia:ConsideracoesFinais}


TODO: Escrever algo aqui :)

