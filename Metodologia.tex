\chapter{Metodologia}
\label{Metodologia}
Neste capítulo será apresentada a metodologia para aplicação da EG para geração de heurísticas de alto nível para um \textit{framework} hiper-heurístico  para o problema de dobramento de proteínas. Esta proposta é baseada no trabalho desenvolvido por Sabar et al. \cite{sabar2015automatic}, o qual  utilizou GEP (\textit{gene expression programming}) com objetivo de gerar os componentes de um \textit{framework} hiper-heurístico para diversos domínios de problemas. Os testes de generalidade realizados por Sabar, utilizando os 6 domínios providos pelo \textit{framework} hiper-heurístico HyFlex, apresentaram bons resultados em relação às outras estratégias hiper-heurísticas do estado da arte. Nesta proposta pretende-se utilizar EG ao invés de GEP e aplicar ao PDP utilizando o modelo HP-2D. A representação de coordenadas relativas, descrita na subseção \ref{subsubsection:modeloHP}, será utilizada pois segundo o estudo realizado por Krasnogor et al. \cite{krasnogor1999protein} apresentam um maior potencial em conduzir os algoritmos a resultados melhores. Para representar as soluções ao problema PDP utilizando coordenadas relativas um esquema de codificação precisa ser definido. Esta representação utiliza um conjunto de movimentos para cada aminoácido baseado no seu predecessor. Os movimentos permitidos para o modelo HP-2D são: frente (F), esquerda(E) e direita(D). Dessa maneira, foi definido o seguinte esquema de codificação utilizando valores inteiros F->0, E->1 e D->2. Portanto o alfabeto utilizado para representar as soluções é definido como $\{0,1,2\}$. Como mencionado anteriormente, um \textit{framework} hiper-heurístico possui dois níveis: alto (\textit{high-level heuristics}) e baixo (\textit{low-level heuristics}). Nesta proposta as heurísticas de alto nível são compostas por: um mecanismo de seleção e um critério de aceitação. Já as heurísticas de baixo nível consistem em um conjunto de heurísticas, selecionadas de estudos anteriores, um mecanismo de memória e uma função de \textit{fitness}. 

\section{\textit{Heurísticas de alto nível}}
\label{sec:highlevelheuristics}
  A presente proposta projeta a geração \textit{online} dos componentes de uma heurística de alto nível (mecanismo de seleção e critério de aceitação) para um \textit{framework} hiper-heurístico. A figura \ref{fig:proposedFramework} apresenta o \textit{framework} proposto.

 \begin{figure}[!htb]
 	\centering
 	\includegraphics[scale=.98]{HH/proposedFramework.png}
 	\caption{\textit{Framework} proposto. \\ Fonte: Adaptado de \cite{sabar2014automatic}}
 	\label{fig:proposedFramework}
 \end{figure}
 
  
    
	Heurísticas de alto nível geralmente levam em consideração uma ou mais informações referentes ao histórico das aplicações das heurísticas de baixo nível para tomar suas decisões. Tradicionalmente, informações tais como desempenho (capacidade de melhorar soluções), tempo (desde a última aplicação de uma dada heurística) e intervalo de confiança (no caso de estratégias que utilizam MAB) são utilizadas como base de conhecimento. Sabar et al. \cite{sabar2015automatic} propõem a utilização de vários critérios para avaliar as heurísticas de baixo nível. A razão disto se dá pelo fato de que cada critério irá favorecer a seleção de uma heurística de baixo nível a partir de uma perspectiva diferente. Por exemplo, algumas heurísticas de baixo nível podem ter bom desempenho apenas no início da busca, enquanto outras podem obter melhores resultados apenas ao final. Estes critérios propostos por Sabar et al. \cite{sabar2015automatic} contém estatísticas referente à aplicações das heurísticas de baixo nível e são genéricos o suficiente para serem aplicados ao PDP. Os critérios propostos por Sabar et al. \cite{sabar2015automatic} são detalhados em seguida:
	
	
\begin{itemize}
	\item RC (\textit{Reward Credit}): Representa a recompensa que uma determinada heurística de baixo nível deve receber baseado no seu desempenho durante o processo de busca. Quando a i-ésima heurística é aplicada, a melhoria para a solução é computada. O cálculo da melhoria é dado por: $M(i) = (|f1 -f2|/f1) *100$ se $f2$< $f1$, onde $f1$ é a qualidade da solução corrente e $f2$ é a qualidade da solução resultante após a aplicação da i-ésima heurística. 
	A melhoria obtida é salva em uma janela deslizante (FIFO) de tamanho W. O crédito de qualquer heurística de baixo nível é então atribuído como o máximo valor na janela deslizante correspondente. A ideia por trás deste critério é: heurísticas de baixo nível que não são usadas com frequência mas que alteram a solução com grandes melhorias tendem a ter mais preferência do que aquelas que geram pequenas melhorias. Portanto as heurísticas que trazem frequentes, mas pequenas melhorias irão ter menos probabilidade de serem selecionadas.
	\item $C_{best}$: Número de vezes que a i-ésima heurística de baixo nível atualizou a melhor solução conhecida. Este critério favorece as heurísticas de baixo nível que obtiveram êxito em melhorar a melhor solução conhecida até o momento. Este critério é útil para sistematicamente melhorar o atual mínimo local.
	\item $C_{current}$: Número de vezes que a i-ésima heurística de baixo nível atualizou a solução atual. Este critério favorece as heurísticas de baixo nível que obtém êxito em atualizar a solução corrente. Este critério serve para deixar a busca concentrada próxima à solução corrente.
	\item $C_{accept}$: Número de vezes que a solução gerada pela i-ésima heurística de baixo nível foi aceita pelo critério de aceitação. Irá favorecer heurísticas de baixo nível que podem ajudar a escapar de um mínimo local.
	\item $C_{ava}$: A média de melhorias anteriores da i-ésima heurística de baixo nível durante o progresso da busca. Este critério favorece heurísticas de baixo nível que realizaram grandes melhorias em média.
	\item $C_r$: O número de vezes que a i-ésima heurística de baixo nível foi classificada como primeira.  
\end{itemize} 

	Da mesma maneira Sabar et al. \cite{sabar2015automatic} propõem o uso de dados referentes ao histórico de aplicações das heurísticas de baixo nível para compor critérios de aceitação que irão definir limites para aceitar soluções com qualidade inferior. Dessa forma, um conjunto de fatores também foi proposto e será detalhado em seguida:
	
	
	 \begin{itemize}
	 	\item Delta: A diferença da qualidade entre a solução corrente e a solução descendente.
	 	\item PF: A qualidade da solução anterior.
	 	\item CF: A qualidade da solução atual.
	 	\item CI: Iteração corrente.
	 	\item TI: Número de iterações.
	 \end{itemize}
	 
	 
Estes dados serão inicializados com valores neutros para evitar qualquer comportamento tendencioso. Os dados  serão atualizados conforme o desempenho e estado das heurísticas de baixo nível durante o progresso da busca.   

	Utilizando estes dados estatísticos e um conjunto de funções matemáticas simples, tais como soma, subtração, multiplicação e divisão, uma gramática foi desenvolvida para suportar a geração das heurísticas de alto nível. A gramática desenvolvida para gerar mecanismos de seleção e critérios de aceitação é apresentada na \autoref{grammar:proposedGrammar}. 
	

	
	% e combinados com funções matemáticas simples compõem a \autoref{grammar:proposedGrammar}

 
 
 % TODO: Talvez levar isso para seçao de EG
 %Como mencionado na subseção \ref{subsubsection:EvolucaoGramatical}, a EG utiliza vetores de valores inteiros com tamanho variável para representar seus indivíduos. Dessa maneira, a EG junta as vantagens tanto de algoritmos genéticos como de programação genética para evoluir populações de programas de computador.
 
 
 

 
 \begin{Grammar}
 	\begin{grammar}
 		<hh-selection> ::= <selection-mechanism> <acceptance-criterion> 
 		
 		<selection-mechanism> :==  <selection-terminal>   
 		\alt <selection-mechanism> <math-function> <selection-mechanism> 
 		\alt (<selection-mechanism> <math-function> <selection-mechanism>) 
 		
 		<selection-terminal> :== 
 		RC 
 		| Cbest 
 		| Ccurrent 
 		| Caccept 
 		| Cava 
 		| Cr
 		
 		<math-function> :== + 
 		| - 
 		| * 
 		| \%
 		
 		<acceptance-criterion> ::== <acceptance-terminal> 
 		\alt <acceptance-criterion> <math-function>
 		<acceptance-criterion>
 		\alt (<acceptance-criterion>  <math-function> <acceptance-criterion>) 
 		
 		<acceptance-terminal> :== PF | CF | CI | TI
 		
 	%	<acceptance-function> :== + | - | * | \% | $e^x$
 		
 		
 	\end{grammar}
 	\caption{Gramática definida para gerar  heurísticas de alto nível}
 	\label{grammar:proposedGrammar}
 \end{Grammar}
 
 
 
 %O conjunto de funções e terminais apresentado na gramática \ref{grammar:proposedGrammar} foi desenvolvido baseado nos conjuntos  propostos no  trabalho relacionado \cite{sabar2014automatic}. 
 %Uma explicação detalhada de cada terminal para os mecanismos de seleção $(selection-terminal)$ é apresentada em seguida:

 
 
 
 O conjunto de funções matemáticas para combinar de diferentes maneiras os dados históricos das aplicações das heurísticas de baixo nível é apresentado abaixo:
  
 \begin{itemize}
	\item +: Adiciona as duas entradas.
	\item -: Subtrai a segunda entrada da primeira.
	\item *: Multiplica as duas entradas.
	\item \%: Divisão protegida, isto é, se o denominador for 0, o altera para 0,001.
 \end{itemize}
 
 
 

% O conjunto de funções para critérios de aceitação $(acceptance-function)$ é apresentado abaixo:
 
%\begin{itemize}
%	\item +: Adiciona as duas entradas.
%	\item -: Subtrai a segunda entrada da primeira.
%	\item $e^x$: O resultado elevado à sua potencia (número de Euler).
%	\item *: Multiplica as duas entradas.
%	\item \%: Divisão protegida, isto é, se o denominador for 0 o altera para 0,001.
% \end{itemize}

 Utilizando a \autoref{grammar:proposedGrammar} e vetores de inteiros é possível gerar heurísticas de alto nível. Os conjuntos terminais da gramática apresentam estatísticas sobre as heurísticas de baixo nível e estas são a matéria-prima para a construção dos componentes das heurísticas de alto nível de um \textit{framework} hiper-heurístico. 
 
 O próximo passo consiste em evoluir uma população de vetores de inteiro, gerados de maneira aleatória, utilizando o processo evolutivo descrito na subseção 
 \ref{subsubsection:EvolucaoGramatical}. %A figura BLAH apresenta o processo geral da evolução gramatical proposta.
 

 \subsection{Função de \textit{Fitness}}
 
 Para avaliar os indivíduos gerados durante o processo de busca da evolução gramatical, uma função de \textit{fitness} foi desenvolvida baseada na função proposta por Sabar el al. \cite{sabar2014automatic}. A probabilidade de selecionar um determinado indivíduo é alterada de acordo com a qualidade da melhor solução retornada pela execução do \textit{framework} hiper-heurístico, composto pelo mecanismo de seleção e critério de aceitação codificados por um dado indivíduo. A qualidade retornada pela solução pode ser pior ou melhor do que a solução utilizada como entrada para o \textit{framework} hiper-heurístico.
 
 Suponha que $f_i$ e $f_b$ representem a qualidade da solução inicial e da retornada e $Ph[]$ o vetor de probabilidades de seleção dos indivíduos da EG. Agora suponha que ao aplicar o $i$-ésimo indivíduo e obtido uma melhoria na qualidade da solução, a retribuição para o $i$-ésimo indivíduo é calculada utilizando a \autoref{eq:fitnessFunction}.
 
 \begin{equation} {}
	 \label{eq:fitnessFunction}
	 Ph[i] = Ph[i] + \sigma 
 \end{equation}
 
 Onde $\sigma = (f_i - f_b)/(f_i + f_b)$. 
 
 E os demais indivíduos são penalizados utilizando a \autoref{eq:fitnessPenalizeFunction}

 \begin{equation} {}
 \label{eq:fitnessPenalizeFunction}
	Ph[j] = Ph[j] - (\sigma / (Nh - 1))
 \end{equation}
 
 Tal que  $j \in \{1, ..., Nh\} ~e~ j \neq i$. E $Nh$  o número de indivíduos da EG.
 
  Caso contrário (se a solução retornada não for melhor que a utilizada como entrada), uma penalização é aplicada ao $i$-ésimo indivíduo utilizando a \autoref{eq:fitnessBadFunction}.
  
   \begin{equation} {}
    \label{eq:fitnessBadFunction}
   Ph[i] = Ph[i] - |\sigma \times \alpha|
    \end{equation}
   
   Onde $\alpha =$ iteração corrente $/$ número total de iterações.
   
  Os demais indivíduos $j \neq i$ recebem uma recompensa utilizando a \autoref{eq:fitnessOtherFunction} 
  
   \begin{equation} {}
   \label{eq:fitnessOtherFunction}
   Ph[j] = Ph[j] + (|\sigma| \times \alpha / (Nh -1))
   \end{equation}
   
    Tal que  $j \in \{1, ..., Nh\} ~e~ j \neq i$. Onde $Nh$ = número de indivíduos da EG e $\alpha =$ iteração corrente $/$ número total de iterações. 
   
 
  
  A motivação por trás de  diminuir a probabilidade de outros indivíduos é reduzir as chances destes serem selecionados. Inicialmente, a probabilidade de cada indivíduo é calculada, decodificando o  respectivo mecanismo de seleção e critério de aceitação e o executando dentro de um \textit{framework} hiper-heurístico por um número determinado de iterações.
 
 \subsection{Critério de Parada}
 \label{sub:criterioParada}
 
 Para terminar o processo da EG um número máximo de iterações que não obtêm melhora será utilizado como condição de parada. Note que este critério de parada é referente à parada do processo da EG e não das execuções dos indivíduos dentro do \textit{framework} hiper-heurístico, que ocorrem durante o progresso da EG. 
 
 \section{\textit{Heurísticas de baixo nível}} 
 
 Nas heurísticas de baixo nível o \textit{framework} proposto possui 2 componentes principais: um conjunto de heurísticas de baixo nível e um mecanismo de memória.
 
 \subsection{Conjunto de heurísticas de baixo nível}
 Um conjunto de heurísticas de baixo nível foi selecionado a partir de uma revisão bibliográfica dos trabalhos mais recentes referentes ao PDP utilizando o modelo HP-2D. 
 
 
 \begin{itemize}
	\item \textit{Two Points Crossover} (2X): Este operador seleciona, de maneria aleatória, 2 pontos de cruzamento dividindo os indivíduos em 3 partes. Os genes entre as posições selecionadas são trocados entre os pais de modo a gerar dois novos filhos \cite{benitez2015algoritmo}, conforme apresentado na figura \ref{fig:twopointscrossover}.
	

	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/TwoPointsCrossover.png}
		\caption{Exemplo de aplicação do operador 2x. \\Fonte Autoria Própria}
		\label{fig:twopointscrossover}
	\end{figure}
	
			

	
	\item \textit{Multi Points Crossover} (MPX): Semelhante ao 2X porém com c pontos, baseado na função $c = int(n * 0.1)$, $n$ é o tamanho da sequência. O operador MPX é utilizado para promover diversidade estrutural realizando uma mescla randômica entre os pais, embora não tão radical quanto o \textit{Uniform  Crossover} \cite{sabar2014automatic}. Um exemplo de aplicação do operador MPX é apresentado na imagem \ref{fig:multipointscrossover}
	
	
		\begin{figure}[!htb]
			\centering
			\includegraphics{Imagens/MultiPointsCrossover.png}
			\caption{Exemplo de aplicação do operador MPX. \\Fonte Autoria Própria}
			\label{fig:multipointscrossover}
		\end{figure}
	\item \textit{Segment Mutation} (SMUT): Altera um número aleatório (5 a 7) de genes consecutivos para direções distintas. Esta heurística introduz grandes mudanças na conformação, e tem uma grande probabilidade de criar colisões. Um mecanismo de reparação simples é aplicado no descendente gerado. A imagem \ref{fig:segmentMutation} apresenta um exemplo da aplicação do SMUT.
	
	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/segmentMutation.png}
		\caption{Exemplo de aplicação do operador SMUT. \\Fonte Autoria Própria}
		\label{fig:segmentMutation}
	\end{figure}
	
	
	\item \textit {Exhaustive Search Mutation} (EMUT): Esta heurística seleciona um gene aleatório e testa todas as outras direções possíveis e irá manter a alteração que conseguir aumentar a qualidade da conformação. O \textit{tradeoff} deste operador é demandar 4 avaliações de \textit{fitness}, as quais devem ser levadas em consideração. Esta heurística tem grande potencial de melhorar o \textit{fitness} de uma conformação. 
	
	
	\item \textit{Local Move Operator} (LM): Esta heurística troca direções entre dois genes aleatórios consecutivos. Existem algumas condições para que esta heurística possa ser executada, por exemplo, as novas direções não podem criar movimentos redundantes. Este operador introduz um "movimento de esquina". A figura \ref{fig:localMoveOperator} apresenta um exemplo da aplicação do operador LM. 
	
	
	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/LocalMoveOperator.png}
		\caption{Exemplo de aplicação do operador LM. \\Fonte Autoria Própria}
		\label{fig:localMoveOperator}
	\end{figure}
	
	
	\item \textit{Loop Move Operator} (LPM): Da mesma maneira que a heurística LM, esta heurística troca direções entre dois genes que estão a 5 genes de distância na sequência, criando um movimento de \textit{loop}. A figura  \ref{fig:loopMoveOperator} apresenta um exemplo da aplicação do operador LPM.

	
	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/LoopMoveOperator.png}
		\caption{Exemplo de aplicação do operador LPM. \\Fonte Autoria Própria}
		\label{fig:loopMoveOperator}
	\end{figure}
	
	\item \textit{Opposite Mutation} (OM): Esta heurística troca as direções, para direção oposta, de uma sequência de genes entre dois genes $(i,j)$ selecionados de maneira aleatória. A direção 0 ($F$) não possui oposta, portanto é mantida. Para exemplificar, suponha esta solução hipotética para uma sequência de 5 aminoácidos: $\{0,1,2,1,2\}$. Ela se tornaria $\{0,2,1,2,1\}$. A figura \ref{fig:oppositeMutation} apresenta um exemplo da aplicação do operador OM.
	
	
	\begin{figure}[!htb]
		\centering
		\includegraphics{Imagens/OppositeMutation.png}
		\caption{Exemplo de aplicação do operador OM. \\Fonte Autoria Própria}
		\label{fig:oppositeMutation}
	\end{figure}
	

	
 \end{itemize} 
 
 
 
 \section{Processo geral da EG proposta} 
 
 As principais etapas da EG proposta serão apresentadas nesta seção.
 Inicialmente uma população de indivíduos (heurísticas de alto nível: mecanismos de seleção e critérios de aceitação) é gerada de maneira aleatória. O \textit{fitness} da população é calculado inserindo os indivíduos em um \textit{framework} hiper-heurístico e o executando por um certo número de iterações. E de maneira iterativa selecionar indivíduos pais e aplicar os operadores de cruzamento, \textit{prune}, mutação, e \textit{duplicate} para gerar descendentes. Para avaliar os descendentes, os seguintes passos são executados:
 
 \begin{enumerate}
 	\item Cada indivíduo é decodificado em um mecanismo de seleção e um critério de aceitação (heurística de alto nível). Os valores, descritos 	para o conjunto terminal na seção \ref{sec:highlevelheuristics}, de cada heurística de baixo nível serão utilizados como entrada para o mecanismo de seleção.
 	\item Execução do mecanismo de seleção com objetivo de ordenar o conjunto de heurísticas de baixo nível. As heurísticas de baixo nível são ordenadas da maior para a menor baseando-se no resultado da expressão referente ao mecanismo de seleção. 
 	\item Selecionar de maneira aleatória uma solução do mecanismo de memória, o qual será detalhado na \autoref{sub:MecanismoDeMemoria}. Aplicar a heurística de baixo nível classificada com o maior valor e calcular a qualidade da solução gerada.
 	\item Se a solução gerada for melhor do que a atual, a atual é substituída. Caso contrário a expressão referente ao critério de aceitação é executada. A solução gerada pela heurística de baixo nível é aceita caso o exponencial natural do valor, retornado pelo critério de aceitação, seja menor ou igual a 0.5 (a função $e^x$ retorna valores entre 0 e 1). Sabar et al. \cite{sabar2014automatic} menciona que este valor de 0.5 é sugerido pela literatura. 
 	\item Aplicar a heurística de baixo nível, que foi selecionada pelo mecanismo de seleção, repetidamente até que não ocorram mais melhorias.
 	\item Se não houverem mais melhorias, troca-se a heurística de baixo nível atual pela segunda melhor classificada, baseando-se no valor retornado pelo mecanismo de seleção.
 	\item Se o \textit{framework} chegar ao fim da lista de heurísticas de baixo nível, é executado o mecanismo de seleção novamente e a lista de heurísticas de baixo nível é reordenada. A busca reinicia agora utilizando a heurística de baixo nível com maior valor para a expressão referente ao mecanismo de seleção.
 	\item O \textit{framework} proposto continuará utilizando os componentes da heurística de alto nível (mecanismo de seleção e critério de aceitação) por um tempo pré-determinado de iterações.
 	\item A solução gerada ao final da busca do \textit{framework} hiper-heurístico  será avaliada para entrar ou não no mecanismo de memória.
 \end{enumerate}
 
 O processo da EG irá parar apenas quando o critério de parada discutido na \autoref{sub:criterioParada} for atingido e será retornado o indivíduo (heurística de alto nível) que possuir o maior valor de \textit{fitness}. Também será retornada a solução ao PDP que tiver maior qualidade no mecanismo de memória.
  
 
 \subsection{Mecanismo de Memória}
 \label{sub:MecanismoDeMemoria}
 
 A maioria dos \textit{frameworks} hiper-heurísticos propostos na literatura operam sobre uma única solução \cite{chakhlevitch2008hyperheuristics, burke2013hyper}. Blum et al. \cite{blum2011hybrid} menciona que utilizar uma única solução pode restringir a capacidade de explorar um espaço de busca grande e restrito. Dessa maneira, Sabar et al. \cite{sabar2014automatic} propôs uma abordagem que utiliza um mecanismo de memória, assim como Talbi el al. \cite{talbi2006cosearch}, o qual contém um conjunto de soluções com alta qualidade e diversificadas, atualizado conforme o progresso da busca. Nesta proposta o mecanismo de memória tem a responsabilidade de armazenar soluções para o problema PDP utilizando a representação de coordenadas relativas para o modelo HP-2D. 
 
 \subsubsection{Inicialização do Mecanismo de Memória}
 
  Tradicionalmente algoritmos evolutivos inicializam suas populações iniciais de maneira aleatória, por conta disto  muitas soluções inválidas ao problema PDP, podem ser geradas na inicialização. Isto geralmente  ocasiona perda de tempo de processamento, por conta da grande quantidade de conformações inválidas antes que bons resultados sejam obtidos. Diante disto,  Benítez et al. \cite{benitez2015algoritmo} propôs uma estratégia especializada de inicialização. Benítez et al. \cite{benitez2015algoritmo} inicializou a população de seu algoritmo genético, dividido-a em duas partes. Uma gerada aleatoriamente, com indivíduos que potencialmente possuem colisões. E uma segunda parte onde todos os indivíduos são livres de colisões. Uma configuração é utilizada para definir a proporção entre as duas partes da população inicial. Para garantir que os indivíduos não possuam colisões, uma estratégia de \textit{backtracking} deve ser utilizada. Nesta proposta, pretende-se utilizar uma estratégia similar, adaptada ao modelo HP-2D.  A estratégia de inicialização com \textit{backtracking} irá começar posicionando o primeiro aminoácido na posição 0,0. Para posicionar o próximo aminoácido, um movimento é selecionado de maneira aleatória. Caso o movimento cause uma colisão, este movimento será marcado como uma má escolha e um novo movimento é selecionado aleatoriamente (do conjunto que restou sem os movimentos marcados como más escolhas). Caso todos os movimentos estejam marcados como má escolha, a estratégia de \textit{backtracking} irá retornar de maneira recursiva para o aminoácido anterior e marcar a escolha em questão como uma má escolha. A estratégia de \textit{backtracking} termina quando gerar uma conformação que não possua colisões.
 
   %As possíveis conformações podem ser representadas por um caminho em um grafo orientado estruturado como uma árvore. Consequentemente, cada nó da árvore representa uma solução candidata parcial $c$, desde o primeiro aminoácido até o último sendo considerado. Portanto, um caminho até um nó folha representa uma conformação completa. As arestas do grafo representam o movimento de cada aminoácido relativo a seu predecessor.
  

 
 \subsubsection{Atualização do Mecanismo de Memória}
 Para cada indivíduo (heurística de alto nível) será selecionada de maneira aleatória uma solução do mecanismo de memória e a busca irá iniciar em torno desta solução, quando o \text{framework} hiper-heurístico atingir o seu número máximo de iterações a solução final tem que ser avaliada para verificar sua qualidade e diversidade. A qualidade de uma solução para o PDP utilizando o modelo HP é inversamente proporcional à quantidade de interações entre aminoácidos hidrofóbicos. Portanto a qualidade de uma solução é dada pela quantidade de iterações H-H multiplicada por -1, conforme descrito na subseção \ref{subsubsection:modeloHP}.  As soluções geradas que tiverem a qualidade maior que todas as soluções contidas no mecanismo de memória substituirão a solução que tiver menor similaridade segundo a distância de \textit{Hamming} \cite{hamming1950error}. Se a qualidade de uma solução gerada não for maior que todas as soluções, mas melhor em relação a um sub-conjunto do mecanismo de memória, esta substituirá a solução que tiver menor qualidade e menor similaridade do sub-conjunto. E por fim se a qualidade da solução gerada for pior que todas contidas no mecanismo de memória, esta é descartada. A similaridade é considerada a fim de manter a diversidade entre as soluções.  
 
 
 
 
% Esta representação possibilita a geração de soluções inválidas, que possuem colisões. Tradicionalmente algoritmos evolutivos inicializam suas populações iniciais de maneira aleatória, por conta disto  muitas soluções inválidas ao problema PDP, podem ser geradas na inicialização. Isto geralmente  ocasiona perda de tempo de processamento, por conta da grande quantidade de conformações inválidas antes que bons resultados sejam obtidos. Diante disto,  Benítez et al. \cite{benitez2015algoritmo} propôs uma estratégia especializada de inicialização. Benítez et al. \cite{benitez2015algoritmo} inicializou a população de seu algoritmo genético, dividido-a em duas partes. Uma gerada aleatoriamente, com indivíduos que potencialmente possuem colisões. E uma segunda parte onde todos os indivíduos são livres de colisões. Uma configuração é utilizada para definir a proporção entre as duas partes da população inicial. Para garantir que os indivíduos não possuam colisões, uma estratégia de \textit{backtracking} deve ser utilizada. Nesta proposta, pretende-se utilizar uma estratégia similar, adaptada ao modelo HP-2D. As possíveis conformações podem ser representadas por um caminho em um grafo orientado estruturado como uma árvore. Consequentemente, cada nó da árvore representa uma solução candidata parcial $c$, desde o primeiro aminoácido até o último sendo considerado. Portanto, um caminho até um nó folha representa uma conformação completa. As arestas do grafo representam o movimento de cada aminoácido relativo a seu predecessor.
 
 % A figura \ref{fig:backtrackInit}  apresenta um fragmento do espaço de busca para uma cadeia hipotética com 5 aminoácidos. O espaço de busca completo é grande totalizando  $5^4=625$ possibilidades, e não pode ser apresentado por questões de visualização.
 
 % 	\begin{figure}[!htb]
 % 		\centering
 % 		\includegraphics[scale=0.8]{Imagens/BacktrackingInit.png}
 % 		\caption{Fragmento do espaço de busca para o modelo HP. \\Fonte Autoria Própria}
 % 		\label{fig:backtrackInit}
 % 	\end{figure}
 
 % 	Na figura \ref{fig:backtrackInit} (TODO: arrumar imagem e explicação para o HP-2D) o caminho apresentado pelas setas azuis representa uma solução que gera uma conformação válida (sem colisões). A seta vermelha demonstra que se caso o ultimo passo fosse alterado de 0 para 1. Esta alteração causaria uma conformação inválida, pois posicionaria o ultimo aminoácido na posição 0,1,1 a qual já havia sido ocupada no segundo passo. 
% A estratégia de inicialização com \textit{backtracking} irá começar posicionando o primeiro aminoácido na posição 0,0. Para posicionar o próximo aminoácido, um movimento é selecionado de maneira aleatória. Caso o movimento cause uma colisão, este movimento será marcado como uma má escolha e um novo movimento é selecionado aleatoriamente (do conjunto que restou sem os movimentos marcados como más escolhas). Caso todos os movimentos estejam marcados como má escolha, a estratégia de \textit{backtracking} irá retornar de maneira recursiva para o aminoácido anterior e marcar a escolha em questão como uma má escolha. A estratégia de \textit{backtracking} termina quando gerar uma conformação que não possua colisões.
 
 
 % 	e selecionando de maneira aleatória o movimento para o próximo 
 % 	
 % 	
 % 	aminoácido. Caso este movimento cause uma colisão (seja posicionado em uma região da grade que já havia um aminoácido) o \textit{backtracking} entra em cena percorrendo a árvore de maneira recursiva 
 
 
 
 % Para cada solução, uma matriz de frequência é associada afim de medir a diversidade da solução. A matriz de frequência irá armazenar a frequência que cada aminoácido foi atribuído para cada uma das direções possíveis $\{0,1,2,3,4\}$. A figura \ref{fig:frequencyMatrix} apresenta um exemplo de uma matriz de frequência para uma cadeia hipotética $HPPHHHP$ de 7 aminoácidos. Observando a figura  \ref{fig:frequencyMatrix} é possível notar que o aminoácido 0 foi atribuído a direção E (3), que significa esquerda, duas vezes, três vezes para a direção D (4), que significa direita e nenhuma vez para as direções F(0), D(1) e B(2). 
 
 
 % 	\begin{figure}[!htb]
 % 		\centering
 % 		\includegraphics[scale=0.8]{Imagens/FrequencyMatrix.png}
 % 		\caption{Fragmento BLAH. \\Fonte Autoria Própria}
 % 		\label{fig:frequencyMatrix}
 % 	\end{figure}
 %
 
 %Para avaliar a diversidade será utilizada a entropia da informação.  As equações \ref{equation:entropy1} e \ref{equation:entropy2} exemplificam o cálculo de entropia.
 
% \begin{equation}
%	 \label{equation:entropy1}
% 	 \epsilon_i = \frac{\sum\limits_{i=1}^e \frac{e_{ij}}{m}  . \log \frac{e_{ij}}{m}}{-log~e}
% \end{equation}
% 
%  \begin{equation}
%  	 \label{equation:entropy2}
%  \epsilon = \frac{\sum\limits_{i=1}^e \epsilon_i}{e}
%  \end{equation}
%  
%	 \noindent$e_{ij}$ é a frequência de alocação do aminoácido $i$ para a direção $j$; \\
%	 $m$ é o número de objetos; \\
%	 $\epsilon_i$ representa a entropia para o aminoácido $i$;
%	 $\epsilon$ representa a entropia para uma solução completa (todos os aminoácidos) ($0 <= \epsilon_i <= 1$). 
% c yyyy 

 
\section{Avaliação da Abordagem Proposta}
\label{Metodologia:Avaliacao}

Um conjunto de experimentos serão executados com sequências de aminoácidos, utilizadas como \textit{benchmark}, para avaliar estratégias heurísticas para o PDP com o modelo HP. Estas sequências foram  utilizadas em outros trabalhos \cite{custodio2004investigation,hsu2003growth,lin2011protein,unger1993genetic,santanna2008,custodio2014multiple, garza2012locality} que também exploram o PDP utilizando o modelo HP. A \autoref{tab:sequences} apresenta o Id de cada sequência, o seu tamanho (quantidade de aminoácidos), o valor ótimo conhecido da respectiva sequência e por fim, fórmula da sequência propriamente dita. 

\begin{table}[!htb]
	\begin{center}
		\caption{Sequências que serão utilizadas para avaliar e comparar os resultados obtidos pela abordagem proposta}
		\label{tab:sequences}
		{$\begin{array}{c r r l}
			\text{Id} & \text{Tamanho} &  \multicolumn{1}{c}{\text{Valor ótimo}} & \multicolumn{1}{c}{\text{Sequência}} \\ \hline
			s1 &20 &-9 & HPHPPHHPHHPHPHHPPHPH \\
			s2 &24 &-9 & HHPPHPPHPPHPPHPPHPPHPPHH \\
			s3 &25 &-8 & PPHPPHHP^4HHP^4HHP^4HH \\
			s4 &36 &-14 &  P^3HHPPHHP^5H^7PPHHP^4HHPPHPP\\
			s5 &48 &-23 &  PPHPPHHPPHHP^5H^{10}P^6 \\
			&   &    &  HHPPHHPPHPPH^5 \\
			s6 &50 &-21 &  HHPHPHPHPH^4PHP^3HP^3HP^4 \\
			&   &    & HP^3HP^3HPH^4{\{PH\}}^4H\\
			s7 &60 &-36 &  PPH^3PH^8P^3H^{10}PHP^3\\
			&   &    &  H^{12}P^4H^6PHHPHP\\
			s8 &64 &-42 &   H^{12}PHPH{\{PPHH\}}^2PPH{\{PPHH\}}^2\\
			&   &    &  PPH{\{PPHH\}}^2PPHPHPH^{12}\\
			s9  &85   &-53  & H^4P^4H^{12}P^6 H^{12} P^3 H^{12} P^3 \\
			&   &    &    H^{12} P^3  H P^2 H^2    P^2 H^2  P^2 H P H  \\
			s10  &100  &-48  &  P^6HPH^{2}P^5H^{3}PH^5PH^{2} P^4 H^{2} \\
			&   &    &   P^2  H^2 P  H^5  P H^{10} P H^{2} P H^{7}  \\
			&   &    &  P^{11} H^{7} P^2  H P   H^3  P^{6} H P H \\
			s11 &100  &-50  &  P^3H^{2}P^2H^{4}P^2H^{3}PH^{2} PH^{2}PH^{4} \\
			&   &    & P^8 H^6 P^{2} H^{6} P^{9} H P H^{2} P  H^{11} P^2  \\
			&   &    &H^3 P  H^{2} P H P^2  H P H^3 P^6 H^3\\ \hline
			\end{array}$}
	\end{center}
\end{table}






\section{Considerações Finais}
\label{Metodologia:ConsideracoesFinais}

Neste capítulo foram discutidos os principais aspectos relativos à metodologia para aplicar a evolução gramatical com objetivo de gerar heurísticas de alto nível de um \text{framework} hiper-heurístico para o PDP. Inicialmente foi discutido por que o esquema de codificação utilizado para representar as soluções ao PDP serão coordenadas relativas. Em seguida, foi apresentada a gramática desenvolvida para gerar as heurísticas de alto nível. Os componentes terminais da gramática representam diferentes aspectos estatísticos referente ao histórico das aplicações das heurísticas de baixo nível. Funções matemáticas simples também compõem a gramática e combinadas com os dados estatísticos gerarão diferentes heurísticas de alto nível. Posteriormente, a função de \textit{fitness} para avaliar as heurísticas de alto nível e o critério de parada foram da EG foram introduzidos. As heurísticas de baixo nível também foram apresentadas. E finalmente o processo geral desta proposta foi apresentado, incluindo os aspectos referentes ao mecanismo de memória. 
O próximo capítulo apresenta as atividades já realizadas e as atividades a serem realizadas assim como, um cronograma para realização das atividades restantes.

